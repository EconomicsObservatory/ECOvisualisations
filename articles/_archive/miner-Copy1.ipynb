{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "69247a50-0990-43d3-bed1-eed00095e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, pandas as pd, json, re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619f920a-c6d0-4c2c-9a6e-94756b79784b",
   "metadata": {},
   "source": [
    "## Parse list of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8f44423f-889d-4cbb-86b8-f8ca445cc535",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.economicsobservatory.com/answers/\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "nrOfPages = int(\n",
    "    soup.find(\"section\", {\"class\": \"answers__listing\"})\n",
    "    .find(\"div\", {\"class\": \"pagination\"})\n",
    "    .find(\"span\")\n",
    "    .text.split(\" of \")[1]\n",
    "    .split(\" \")[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "92c9da0a-9527-4772-b139-85ca339771e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "# articles = json.loads(open(\"articles.json\", \"r\").read())\n",
    "articles = {i[\"name\"]: i for i in articles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9766b121-ba0e-4916-b825-f92034ef203e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  of  9\n",
      "2  of  9\n",
      "3  of  9\n",
      "4  of  9\n",
      "5  of  9\n",
      "6  of  9\n",
      "7  of  9\n",
      "8  of  9\n",
      "9  of  9\n"
     ]
    }
   ],
   "source": [
    "for page in range(1, nrOfPages + 1):\n",
    "    url = \"https://www.economicsobservatory.com/answers/page/\" + str(page)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    for k in (\n",
    "        soup.find(\"section\", {\"class\": \"answers__listing\"})\n",
    "        .find(\"div\", {\"class\": \"answers__listing-left\"})\n",
    "        .find(\"ul\")\n",
    "        .findAll(\"li\")\n",
    "    ):\n",
    "        paragraphs = k.find(\"div\").findAll(\"div\")\n",
    "        para0 = paragraphs[0].text.split(\" â€¢ \")\n",
    "        category = para0[0].strip()\n",
    "        date = str(pd.to_datetime(para0[1]))[:10]\n",
    "        title = paragraphs[1].find(\"a\").text\n",
    "        link = paragraphs[1].find(\"a\")[\"href\"]\n",
    "        name = link.split(\"/\")[-1]\n",
    "        if name not in articles:\n",
    "            articles[name] = {\n",
    "                \"name\": name,\n",
    "                \"category\": category,\n",
    "                \"date\": date,\n",
    "                \"title\": title,\n",
    "                \"url\": link,\n",
    "            }\n",
    "    print(page, \" of \", nrOfPages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f91efe1-a691-48f3-a8d1-e4b9e4dbf749",
   "metadata": {},
   "source": [
    "Make local backup or article metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e56841f8-b568-4d07-aba2-510049e8231e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118909"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"articles.json\", \"w\").write(json.dumps(list(articles.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8e3ea-b555-4709-a50c-18ca9b9caa74",
   "metadata": {},
   "source": [
    "## Parse individual articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "9da9ff24-f202-4e3e-bd28-c7c59ac53663",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "# authors = json.loads(open(\"authors.json\", \"r\").read())\n",
    "authors = {i[\"name\"]: i for i in authors}\n",
    "figures = []\n",
    "# figures = json.loads(open(\"figures.json\", \"r\").read())\n",
    "figures = {i[\"name\"]: i for i in figures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "1255dc63-9bac-4601-bc69-2ebea359a90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how-can-labour-market-policy-help-get-people-back-right-jobs\n"
     ]
    }
   ],
   "source": [
    "# for a in articles:\n",
    "for a in ['how-can-labour-market-policy-help-get-people-back-right-jobs']:\n",
    "    article = articles[a]\n",
    "#     if \"text\" not in article:\n",
    "    if True:\n",
    "\n",
    "        # Load article page\n",
    "        url = article[\"url\"]\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        # Extract content\n",
    "        relatedCategories = [\n",
    "            i.find(\"a\").text\n",
    "            for i in soup.find(\"ul\", {\"class\": \"article__sidebar-categories\"}).findAll(\n",
    "                \"li\"\n",
    "            )\n",
    "        ]\n",
    "        # articleIntro = soup.find(\"div\", {\"class\", \"article__intro\"}).find(\"h3\").text\n",
    "        if soup.find(\"div\", {\"class\", \"article__intro\"}):\n",
    "            articleIntro = re.sub(\n",
    "                \"\\xa0\",\n",
    "                \" \",\n",
    "                re.sub(\"\\n\", \"\", soup.find(\"div\", {\"class\", \"article__intro\"}).text),\n",
    "            ).strip()\n",
    "        articleText = \"\\n\".join(\n",
    "            [i.text for i in soup.find(\"div\", {\"class\", \"article__body\"}).findAll(\"p\")]\n",
    "        )\n",
    "\n",
    "        # Extract authors\n",
    "        articleAuthors = []\n",
    "        if soup.find(\"ul\", {\"class\": \"article__authors-list\"}):\n",
    "            for authorData in soup.find(\n",
    "                \"ul\", {\"class\": \"article__authors-list\"}\n",
    "            ).findAll(\"li\"):\n",
    "                author = authorData.find(\"div\", {\"class\": \"title\"}).text\n",
    "                articleAuthors.append(author)\n",
    "                if author not in authors:\n",
    "                    affiliation = authorData.find(\"div\", {\"class\": \"aff\"}).text\n",
    "                    profile = authorData.find(\"a\", {\"class\": \"link\"})[\"href\"]\n",
    "                    image = (\n",
    "                        authorData.find(\"div\", {\"class\", \"image\"})[\"style\"]\n",
    "                        .split(\"url\")[1]\n",
    "                        .split(\"'\")[1]\n",
    "                    )\n",
    "                    authors[author] = {\n",
    "                        \"name\": author,\n",
    "                        \"affiliation\": affiliation,\n",
    "                        \"profile\": profile,\n",
    "                        \"image\": image,\n",
    "                        \"articles\": [],\n",
    "                        \"expert\": [],\n",
    "                        \"categories\": [],\n",
    "                        \"related\": [],\n",
    "                    }\n",
    "                if article[\"name\"] not in authors[author][\"articles\"]:\n",
    "                    authors[author][\"articles\"].append(article[\"name\"])\n",
    "                if article[\"category\"] not in authors[author][\"categories\"]:\n",
    "                    authors[author][\"categories\"].append(article[\"category\"])\n",
    "                for relatedCategory in relatedCategories:\n",
    "                    if relatedCategory not in authors[author][\"related\"]:\n",
    "                        authors[author][\"related\"].append(relatedCategory)\n",
    "\n",
    "        # Extract figures\n",
    "        fig0 = \"Figure 1: \"\n",
    "        abc = \"abcdefghijklmnopqrstuv\"\n",
    "        counter = 0\n",
    "        articleFigures = []\n",
    "        for fig in [i.text for i in soup.findAll(\"h4\")]:\n",
    "            if fig.strip()[:5] != \"Table\":\n",
    "                if \":\" not in fig:\n",
    "                    fig = fig0.split(\":\")[0] + abc[counter] + \": \"\n",
    "                    counter += 1\n",
    "                else:\n",
    "                    fig0 = fig\n",
    "                figId = \"fig\" + fig.split(\":\")[0].split(\" \")[1]\n",
    "                figName = article[\"name\"] + \"_\" + figId\n",
    "                articleFigures.append(figName)\n",
    "                if figName not in figures:\n",
    "                    figTitle = fig.split(\":\")[1].strip()\n",
    "                    figures[figName] = {\n",
    "                        \"name\": figName,\n",
    "                        \"title\": figTitle,\n",
    "                        \"articles\": [article[\"name\"]],\n",
    "                    }\n",
    "                elif article[\"name\"] not in figures[figName][\"articles\"]:\n",
    "                    figures[figName][\"articles\"].append(article[\"name\"])\n",
    "\n",
    "        # Extract experts\n",
    "        articleExperts = []\n",
    "        if soup.find(\"ul\", {\"class\": \"article__sidebar-experts\"}):\n",
    "            for authorData in soup.find(\n",
    "                \"ul\", {\"class\": \"article__sidebar-experts\"}\n",
    "            ).findAll(\"li\"):\n",
    "                author = authorData.find(\"div\", {\"class\": \"title\"}).text\n",
    "                articleExperts.append(author)\n",
    "                if author not in authors:\n",
    "                    affiliation = authorData.find(\"div\", {\"class\": \"aff\"}).text\n",
    "                    profile = authorData.find(\"a\", {\"class\": \"link\"})[\"href\"]\n",
    "                    image = (\n",
    "                        authorData.find(\"div\", {\"class\", \"image\"})[\"style\"]\n",
    "                        .split(\"url\")[1]\n",
    "                        .split(\"'\")[1]\n",
    "                    )\n",
    "                    authors[author] = {\n",
    "                        \"name\": author,\n",
    "                        \"affiliation\": affiliation,\n",
    "                        \"profile\": profile,\n",
    "                        \"image\": image,\n",
    "                        \"articles\": [],\n",
    "                        \"expert\": [],\n",
    "                        \"categories\": [],\n",
    "                        \"related\": [],\n",
    "                    }\n",
    "                if article[\"name\"] not in authors[author][\"expert\"]:\n",
    "                    authors[author][\"expert\"].append(article[\"name\"])\n",
    "                if article[\"category\"] not in authors[author][\"categories\"]:\n",
    "                    authors[author][\"categories\"].append(article[\"category\"])\n",
    "                for relatedCategory in relatedCategories:\n",
    "                    if relatedCategory not in authors[author][\"related\"]:\n",
    "                        authors[author][\"related\"].append(relatedCategory)\n",
    "\n",
    "        # Augment article data\n",
    "        article[\"authors\"] = articleAuthors\n",
    "        article[\"figures\"] = articleFigures\n",
    "        article[\"experts\"] = articleExperts\n",
    "        article[\"related\"] = relatedCategories\n",
    "        article[\"intro\"] = articleIntro\n",
    "        article[\"text\"] = articleText\n",
    "\n",
    "        print(article[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "85ca2511-dc1a-4131-b1c0-9a2aeaa4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 1: UK claimant count (thousands)\n",
      "Figure 2: Change in vacancy postings, 2019-2020 (%)\n"
     ]
    }
   ],
   "source": [
    "for fig in [i.text for i in soup.findAll(\"h4\")]:\n",
    "    print(fig)\n",
    "    #     if fig.strip()[:5] != \"Table\":\n",
    "#         if \":\" not in fig:\n",
    "#             fig = fig0.split(\":\")[0] + abc[counter] + \": \"\n",
    "#             counter += 1\n",
    "#         else:\n",
    "#             fig0 = fig\n",
    "#         figId = \"fig\" + fig.split(\":\")[0].split(\" \")[1]\n",
    "#         figName = article[\"name\"] + \"_\" + figId\n",
    "#         articleFigures.append(figName)\n",
    "#         if figName not in figures:\n",
    "#             figTitle = fig.split(\":\")[1].strip()\n",
    "#             figures[figName] = {\n",
    "#                 \"name\": figName,\n",
    "#                 \"title\": figTitle,\n",
    "#                 \"articles\": [article[\"name\"]],\n",
    "#             }\n",
    "#         elif article[\"name\"] not in figures[figName][\"articles\"]:\n",
    "#             figures[figName][\"articles\"].append(article[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "e9c3102a-6b1b-4206-9a57-f9a4f1297327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h4>Figure 1: UK claimant count (thousands)</h4>,\n",
       " <h4>Figure 2: Change in vacancy postings, 2019-2020 (%)</h4>]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll(\"div\",{})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4085c67-f82d-43e9-8685-3ea39c97afc7",
   "metadata": {},
   "source": [
    "Update data on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "7838a04c-cbd0-4e58-87b5-cd8458a55212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4154880"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"articles.json\", \"w\").write(json.dumps(list(articles.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "68da1a56-29d1-4845-af5b-020429eb2ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430887"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for author in authors:\n",
    "    authors[author][\"observatory\"] = \"https://www.economicsobservatory.com/\" + re.sub(\n",
    "        \" \", \"-\", authors[author][\"name\"].lower()\n",
    "    )\n",
    "open(\"authors.json\", \"w\").write(json.dumps(list(authors.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c5fc97fe-523c-4c7a-818e-b257673284e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137858"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"figures.json\", \"w\").write(json.dumps(list(figures.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1263e-8d7b-4ea2-8453-ec8b88c5a3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
